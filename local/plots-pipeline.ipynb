{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/LRTAnalysis/analysis/analysis.p')\n",
    "subdf = pd.read_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/LRTAnalysis/analysis/subanalysis.p')\n",
    "# NOTE THAT 'IN' MEAN IN TO THE ALT DISTRIBUTION, WHCIH IS NOT WHAT MATHEMATICA DOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getcount(decision, direction):\n",
    "    directiondir = {'in':'-1', 'out':'1', 'unk':'0', 'fail':'2'}\n",
    "    query = '%s == %s' %(decision, directiondir[direction])\n",
    "    num = len(np.asarray(df.query(query)[decision], dtype=int))\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1395, 1069, 1292, 1702]\n",
      "[479, 2333, 2016, 0]\n",
      "[2514, 762, 1016, 2759]\n"
     ]
    }
   ],
   "source": [
    "# plot some stuff\n",
    "expin = getcount('dexp', 'in')\n",
    "expout = getcount('dexp', 'out')\n",
    "expunk = getcount('dexp', 'unk')\n",
    "lnin = getcount('dln', 'in')\n",
    "lnout = getcount('dln', 'out')\n",
    "lnunk = getcount('dln', 'unk')\n",
    "strexpin = getcount('dstrexp', 'in')\n",
    "strexpout = getcount('dstrexp', 'out')\n",
    "strexpunk = getcount('dstrexp', 'unk')\n",
    "plwcin = getcount('dplwc', 'in')\n",
    "plwcout = getcount('dplwc', 'out')\n",
    "plwcunk = getcount('dplwc', 'unk')\n",
    "# order = \"LN\", \"Exp\", \"Str Exp\", \"PLwC\"\n",
    "incounts = [lnin, expin, strexpin, plwcin]\n",
    "outcounts = [lnout, expout, strexpout, plwcout]\n",
    "unkcounts = [lnunk, expunk, strexpunk, plwcunk]\n",
    "print incounts\n",
    "print outcounts\n",
    "print unkcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.query(\"alpha != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doms = np.unique(df.Domain)\n",
    "# number of graphs and mean alpha value in each domain\n",
    "counts = np.zeros_like(doms)\n",
    "means = np.zeros_like(doms)\n",
    "counts_plaus = np.zeros_like(doms)\n",
    "means_plaus = np.zeros_like(doms)\n",
    "counts_plaustail = np.zeros_like(doms)\n",
    "means_plaustail = np.zeros_like(doms)\n",
    "for i,dom in enumerate(doms):\n",
    "    query = \"Domain == '%s'\" %dom\n",
    "    subdf = df.query(query)\n",
    "    counts[i] = len(subdf)\n",
    "    means[i] = format(np.mean(subdf.alpha), '.2f')\n",
    "    subdf_plaus = subdf.query(\"ppl>0.1\")\n",
    "    counts_plaus[i] = len(subdf_plaus)\n",
    "    means_plaus[i] = format(np.mean(subdf_plaus.alpha), '.2f')\n",
    "    subdf_plaustail = subdf_plaus.query(\"ntail>=50\")\n",
    "    counts_plaustail[i] = len(subdf_plaustail)\n",
    "    means_plaustail[i] = format(np.mean(subdf_plaustail.alpha), '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Biological' 'Economic' 'Informational' 'Social' 'Technological'\n",
      " 'Transportation']\n",
      "[125 0 13 239 1316 1]\n",
      "['2.70' 'nan' '2.69' '4.19' '2.19' '4.82']\n"
     ]
    }
   ],
   "source": [
    "print doms\n",
    "print counts_plaustail\n",
    "print means_plaustail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_strong(rows):\n",
    "    SA = False # strong alone\n",
    "    S1 = False # strong 1\n",
    "    S2 = False # strong 2\n",
    "    n = len(rows)\n",
    "    strong = 0\n",
    "    strong_alone = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50 and row.alpha < 3 and row.alpha > 2:\n",
    "            strong_alone += 1\n",
    "            if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1  and row.dplwc >-1:\n",
    "                strong += 1\n",
    "    if strong_alone >= 9.*n/10:\n",
    "        SA = True\n",
    "    if strong >= n/2.:\n",
    "        S2 = True\n",
    "    if SA == True and strong >= 95.*n/100:\n",
    "        S1 = True\n",
    "    return (S1, S2, SA)\n",
    "            \n",
    "def test_weak(rows):\n",
    "    W = False \n",
    "    West = False \n",
    "    n = len(rows)\n",
    "    weak = 0\n",
    "    weakest = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1:\n",
    "            weakest += 1\n",
    "            if row.ntail>=50:\n",
    "                weak += 1\n",
    "    if weak >= n/2.:\n",
    "        W = True\n",
    "    if weakest >= n/2.:\n",
    "        West = True\n",
    "    return (W, West)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test diff hypotheses\n",
    "unique_datasets = np.unique(df.fp_gml)\n",
    "hyps = pd.DataFrame(columns = ['Strong1', \"Strong2\", \"Strong_alone\", \"Weak\", \"Weakest\", \"Domain\", \"Subdomain\", \"median_alpha\"], index=unique_datasets )\n",
    "for i, dataset in enumerate(unique_datasets):\n",
    "    query = \"fp_gml == '%s'\" %dataset\n",
    "    rows = df.query(query)\n",
    "    [S1, S2, SA] = test_strong(rows)\n",
    "    hyps.loc[dataset]['Strong1'] = S1\n",
    "    hyps.loc[dataset]['Strong2'] = S2\n",
    "    hyps.loc[dataset]['Strong_alone'] = SA\n",
    "    [weak,weakest] = test_weak(rows)\n",
    "    hyps.loc[dataset]['Weak'] = weak\n",
    "    hyps.loc[dataset]['Weakest'] = weakest\n",
    "    hyps.loc[dataset]['Domain'] = rows.Domain[0]\n",
    "    hyps.loc[dataset]['Subdomain'] = rows.Subdomain[0]\n",
    "    hyps.loc[dataset]['median_alpha'] = np.median(rows.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong1 = 0.402777777778\n",
      "Strong2 = 0.448717948718\n",
      "Strong_alone = 0.405982905983\n",
      "Weak = 0.522435897436\n",
      "Weakest = 0.622863247863\n",
      "Number of Datsets = 1872\n"
     ]
    }
   ],
   "source": [
    "n = float(len(hyps))\n",
    "Strong1 = np.sum(hyps.Strong1)\n",
    "Strong2 = np.sum(hyps.Strong2)\n",
    "Strong_alone = np.sum(hyps.Strong_alone)\n",
    "Weak = np.sum(hyps.Weak)\n",
    "Weakest = np.sum(hyps.Weakest)\n",
    "print \"Strong1 = %s\" %(Strong1/n)\n",
    "print \"Strong2 = %s\" %(Strong2/n)\n",
    "print \"Strong_alone = %s\" %(Strong_alone/n)\n",
    "print \"Weak = %s\" %(Weak/n)\n",
    "print \"Weakest = %s\" %(Weakest/n)\n",
    "print \"Number of Datsets = %s\" %int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyps.to_csv('/Users/annabroido/Dropbox/Research/LRTAnalysis/LRTAnalysis/analysis/hyps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3500000000000032"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = unique_datasets[0]\n",
    "query = \"fp_gml == '%s'\" %dataset\n",
    "rows = df.query(query)\n",
    "np.median(rows.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyps.query(\"Domain=='Biological'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong1 = 0.0278551532033\n",
      "Strong2 = 0.091922005571\n",
      "Strong_alone = 0.0278551532033\n",
      "Weak = 0.345403899721\n",
      "Weakest = 0.688022284123\n",
      "Number of Datsets = 359\n"
     ]
    }
   ],
   "source": [
    "subhyps = hyps.query(\"Domain=='Social'\")\n",
    "n = float(len(subhyps))\n",
    "Strong1 = np.sum(subhyps.Strong1)\n",
    "Strong2 = np.sum(subhyps.Strong2)\n",
    "Strong_alone = np.sum(subhyps.Strong_alone)\n",
    "Weak = np.sum(subhyps.Weak)\n",
    "Weakest = np.sum(subhyps.Weakest)\n",
    "print \"Strong1 = %s\" %(Strong1/n)\n",
    "print \"Strong2 = %s\" %(Strong2/n)\n",
    "print \"Strong_alone = %s\" %(Strong_alone/n)\n",
    "print \"Weak = %s\" %(Weak/n)\n",
    "print \"Weakest = %s\" %(Weakest/n)\n",
    "print \"Number of Datsets = %s\" %int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
